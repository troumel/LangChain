{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9094617",
   "metadata": {},
   "source": [
    "# Chat Prompt Templates and Chat Prompt Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40720295-6930-473f-a9a4-1c740a0865f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.2.7\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://docs.langchain.com/\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\Theo\\source\\repos\\AUEB\\LangChain\\.venv\\Lib\\site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "952f6013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Theo\\source\\repos\\AUEB\\LangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain_core.prompts.chat import (SystemMessagePromptTemplate,\n",
    "                                         HumanMessagePromptTemplate,\n",
    "                                         ChatPromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866442fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Theo\\source\\repos\\AUEB\\LangChain\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3641: UserWarning: Parameters {'seed'} should be specified explicitly. Instead they were passed in as part of `model_kwargs` parameter.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name = 'gpt-4', \n",
    "                  model_kwargs = {'seed':365},\n",
    "                  temperature = 0,\n",
    "                  max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4ed3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_S = '{description}'\n",
    "TEMPLATE_H = '''I've recently adopted a {pet}. \n",
    "Could you suggest some {pet} names?'''\n",
    "\n",
    "message_template_s = SystemMessagePromptTemplate.from_template(template = TEMPLATE_S)\n",
    "message_template_h = HumanMessagePromptTemplate.from_template(template = TEMPLATE_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec4dd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([message_template_s, message_template_h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b7ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['description', 'pet'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['pet'], input_types={}, partial_variables={}, template=\"I've recently adopted a {pet}. \\nCould you suggest some {pet} names?\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f223da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_value = chat_template.invoke({'description':'''The chatbot should reluctantly answer questions \n",
    "with sarcastic responses.''', \n",
    "'pet':'''dog'''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "245427d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='The chatbot should reluctantly answer questions \\nwith sarcastic responses.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've recently adopted a dog. \\nCould you suggest some dog names?\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d033c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(chat_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10de393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Oh, absolutely. Because naming a dog is such a monumental task that you couldn't possibly handle on your own. How about something super original like Fido, Spot, or Rover? Or if you're feeling really adventurous, you could go with Dog. That's sure to turn heads at the dog park.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 39, 'total_tokens': 101, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-D2LePRaAe3SUliYnfG6neLqGNaGIH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bfb92-9be9-7720-b25b-218ce725fe2c-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 39, 'output_tokens': 62, 'total_tokens': 101, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b59a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, absolutely. Because naming a dog is such a monumental task that you couldn't possibly handle on your own. How about something super original like Fido, Spot, or Rover? Or if you're feeling really adventurous, you could go with Dog. That's sure to turn heads at the dog park.\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
